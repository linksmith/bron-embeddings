{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 3446697/3446697 [07:02<00:00, 8156.42it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('GM0141', 'Almelo')\n",
      "('GM1896', 'Zwartewaterland')\n",
      "('GM0180', 'Staphorst')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize the Elasticsearch client\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "index_name = \"bron_2024_10_11\"\n",
    "unique_pairs = set()\n",
    "\n",
    "# Get the total count of documents\n",
    "total_docs = es.count(index=index_name)['count']\n",
    "\n",
    "# Use a scroll or search_after to retrieve all documents\n",
    "resp = es.search(index=index_name, body={\"query\": {\"match_all\": {}}, \"size\": 1000}, scroll='1m')\n",
    "\n",
    "sid = resp['_scroll_id']\n",
    "hits = resp['hits']['hits']\n",
    "\n",
    "# Initialize tqdm with total_docs\n",
    "with tqdm(total=total_docs, desc=\"Processing documents\") as pbar:\n",
    "    while hits:\n",
    "        for doc in hits:\n",
    "            source = doc['_source']\n",
    "            location = source.get('location')\n",
    "            location_name = source.get('location_name')\n",
    "            if location and location_name:\n",
    "                unique_pairs.add((location, location_name))\n",
    "            pbar.update(1)  # Update the progress bar for each processed document\n",
    "\n",
    "        resp = es.scroll(scroll_id=sid, scroll='1m')\n",
    "        # Update the scroll ID and hits\n",
    "        sid = resp['_scroll_id']\n",
    "        hits = resp['hits']['hits']\n",
    "\n",
    "# Convert to a list if needed and print\n",
    "unique_pairs_list = list(unique_pairs)\n",
    "for pair in unique_pairs_list:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_pairs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "QdrantFastembedMixin.query() missing 1 required positional argument: 'query_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m qdrant_client \u001b[38;5;241m=\u001b[39m QdrantClient(host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m\"\u001b[39m, port\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6333\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000000\u001b[39m)\n\u001b[1;32m      4\u001b[0m collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnederland_2025_02_01_cohere\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m query_result \u001b[38;5;241m=\u001b[39m\u001b[43mqdrant_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_payload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmeta.source_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_vectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m ids \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m point \u001b[38;5;129;01min\u001b[39;00m query_result\u001b[38;5;241m.\u001b[39mresult:\n",
      "\u001b[0;31mTypeError\u001b[0m: QdrantFastembedMixin.query() missing 1 required positional argument: 'query_text'"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "qdrant_client = QdrantClient(host=\"localhost\", port=6333, timeout=1000000)\n",
    "\n",
    "collection_name=\"nederland_2025_02_01_cohere\"\n",
    "\n",
    "query_result =qdrant_client.query(\n",
    "    collection_name=collection_name,\n",
    "    with_payload=['meta.source_id'],\n",
    "    with_vectors=False,\n",
    ")\n",
    "\n",
    "ids = []\n",
    "\n",
    "for point in query_result.result:\n",
    "    ids.append(point.payload['meta']['source_id'])\n",
    "\n",
    "ids = list(set(ids))\n",
    "len(ids)\n",
    "qdrant_client.scroll(\n",
    "                    collection_name=collection_name,\n",
    "                    limit=100,\n",
    "                    with_payload=['meta.source_id'],\n",
    "                    with_vectors=False,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 64\u001b[0m\n\u001b[1;32m     60\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m unique_source_ids\n\u001b[0;32m---> 64\u001b[0m ids \u001b[38;5;241m=\u001b[39m \u001b[43mget_unique_source_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mlen\u001b[39m(ids)\n",
      "Cell \u001b[0;32mIn[2], line 60\u001b[0m, in \u001b[0;36mget_unique_source_ids\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m                 f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# Small delay to prevent overwhelming the DB\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unique_source_ids\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Filter, FieldCondition, MatchValue, ScoredPoint\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Qdrant configuration\n",
    "QDRANT_HOST = \"http://localhost:6333\"  # Change if necessary\n",
    "COLLECTION_NAME = \"nederland_2025_02_01_cohere\"  # Change to your collection name\n",
    "BATCH_SIZE = 10000  # Adjust batch size based on performance\n",
    "\n",
    "# Initialize client\n",
    "qdrant_client = QdrantClient(QDRANT_HOST)\n",
    "\n",
    "def get_unique_source_ids():\n",
    "    \"\"\" Fetch unique source_ids from Qdrant collection efficiently \"\"\"\n",
    "    unique_source_ids = set()\n",
    "    offset = None  # Qdrant uses `offset` for pagination\n",
    "    retrieved = 0\n",
    "\n",
    "    doc_count = qdrant_client.count(COLLECTION_NAME, timeout=1000000).count\n",
    "    pbar = tqdm(desc=\"Retrieving points\", unit=\"docs\", dynamic_ncols=True, total=doc_count)\n",
    "    \n",
    "    while True:\n",
    "        # Perform a scroll-like query to fetch points iteratively\n",
    "        response = qdrant_client.scroll(\n",
    "            collection_name=COLLECTION_NAME,\n",
    "            with_payload=[\"meta.source_id\"],\n",
    "            limit=BATCH_SIZE,\n",
    "            offset=offset  # Use offset for pagination\n",
    "        )\n",
    "\n",
    "        points, next_offset = response  # Qdrant returns (List[ScoredPoint], Offset)\n",
    "\n",
    "        # Extract unique source_ids\n",
    "        for point in points:\n",
    "            source_id = point.payload['meta']['source_id']\n",
    "            if source_id:\n",
    "                unique_source_ids.add(source_id)\n",
    "\n",
    "        retrieved += len(points)\n",
    "        \n",
    "        pbar.update(len(points))  # Update tqdm progress bar\n",
    "        pbar.set_postfix(unique_ids=len(unique_source_ids))\n",
    "\n",
    "        # Stop when there's no more data\n",
    "        if next_offset is None or not points:\n",
    "            break\n",
    "\n",
    "        # Update offset for the next batch\n",
    "        offset = next_offset\n",
    "        \n",
    "        # Write current batch of IDs to file\n",
    "        with open('source_ids.txt', 'a') as f:\n",
    "            for point in points:\n",
    "                source_id = point.payload['meta']['source_id']\n",
    "                if source_id:\n",
    "                    f.write(f\"{source_id}\\n\")\n",
    "    \n",
    "    return unique_source_ids\n",
    "\n",
    "ids = get_unique_source_ids()\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cohere-onnx-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
