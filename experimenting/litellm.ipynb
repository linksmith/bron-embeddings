{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting arize-phoenix\n",
      "  Downloading arize_phoenix-5.8.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting litellm\n",
      "  Downloading litellm-1.52.8-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting openinference-semantic-conventions\n",
      "  Downloading openinference_semantic_conventions-0.1.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting openinference-instrumentation-litellm\n",
      "  Downloading openinference_instrumentation_litellm-0.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting arize-phoenix-otel\n",
      "  Downloading arize_phoenix_otel-0.6.1-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting arize-phoenix-evals\n",
      "  Downloading arize_phoenix_evals-0.17.4-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting aioitertools (from arize-phoenix)\n",
      "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting aiosqlite (from arize-phoenix)\n",
      "  Downloading aiosqlite-0.20.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting alembic<2,>=1.3.0 (from arize-phoenix)\n",
      "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting authlib (from arize-phoenix)\n",
      "  Downloading Authlib-1.3.2-py2.py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting cachetools (from arize-phoenix)\n",
      "  Downloading cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: fastapi in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from arize-phoenix) (0.115.0)\n",
      "Collecting grpc-interceptor (from arize-phoenix)\n",
      "  Downloading grpc_interceptor-0.15.4-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: grpcio in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from arize-phoenix) (1.66.2)\n",
      "Requirement already satisfied: httpx in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from arize-phoenix) (0.27.2)\n",
      "Requirement already satisfied: jinja2 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from arize-phoenix) (3.1.4)\n",
      "Requirement already satisfied: numpy!=2.0.0 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from arize-phoenix) (2.0.2)\n",
      "Collecting openinference-instrumentation>=0.1.12 (from arize-phoenix)\n",
      "  Downloading openinference_instrumentation-0.1.18-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp (from arize-phoenix)\n",
      "  Downloading opentelemetry_exporter_otlp-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-proto>=1.12.0 (from arize-phoenix)\n",
      "  Downloading opentelemetry_proto-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk (from arize-phoenix)\n",
      "  Downloading opentelemetry_sdk-1.28.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-semantic-conventions (from arize-phoenix)\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: pandas>=1.0 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from arize-phoenix) (2.2.3)\n",
      "Requirement already satisfied: protobuf<6.0,>=3.20.2 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from arize-phoenix) (4.25.5)\n",
      "Requirement already satisfied: psutil in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from arize-phoenix) (6.0.0)\n",
      "Collecting pyarrow (from arize-phoenix)\n",
      "  Using cached pyarrow-18.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: pydantic!=2.0.*,<3,>=1.0 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from arize-phoenix) (2.9.2)\n",
      "Requirement already satisfied: python-multipart in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from arize-phoenix) (0.0.12)\n",
      "Collecting scikit-learn (from arize-phoenix)\n",
      "  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting scipy (from arize-phoenix)\n",
      "  Downloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting sqlalchemy<3,>=2.0.4 (from sqlalchemy[asyncio]<3,>=2.0.4->arize-phoenix)\n",
      "  Downloading SQLAlchemy-2.0.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting sqlean-py>=3.45.1 (from arize-phoenix)\n",
      "  Downloading sqlean.py-3.47.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: starlette in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from arize-phoenix) (0.38.6)\n",
      "Collecting strawberry-graphql==0.243.1 (from arize-phoenix)\n",
      "  Downloading strawberry_graphql-0.243.1-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: tqdm in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from arize-phoenix) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from arize-phoenix) (4.12.2)\n",
      "Requirement already satisfied: uvicorn in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from arize-phoenix) (0.31.0)\n",
      "Collecting websockets (from arize-phoenix)\n",
      "  Downloading websockets-14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: wrapt in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from arize-phoenix) (1.16.0)\n",
      "Collecting graphql-core<3.4.0,>=3.2.0 (from strawberry-graphql==0.243.1->arize-phoenix)\n",
      "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from strawberry-graphql==0.243.1->arize-phoenix) (2.9.0.post0)\n",
      "Collecting aiohttp (from litellm)\n",
      "  Downloading aiohttp-3.11.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: click in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from litellm) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from litellm) (6.11.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from litellm) (4.23.0)\n",
      "Collecting openai>=1.54.0 (from litellm)\n",
      "  Downloading openai-1.54.4-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting python-dotenv>=0.2.0 (from litellm)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from litellm) (2.32.3)\n",
      "Collecting tiktoken>=0.7.0 (from litellm)\n",
      "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: tokenizers in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from litellm) (0.20.0)\n",
      "Collecting opentelemetry-api (from openinference-instrumentation-litellm)\n",
      "  Downloading opentelemetry_api-1.28.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-instrumentation (from openinference-instrumentation-litellm)\n",
      "  Downloading opentelemetry_instrumentation-0.49b1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting Mako (from alembic<2,>=1.3.0->arize-phoenix)\n",
      "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from importlib-metadata>=6.8.0->litellm) (3.20.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from jinja2->arize-phoenix) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.20.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from openai>=1.54.0->litellm) (4.6.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from openai>=1.54.0->litellm) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from openai>=1.54.0->litellm) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from openai>=1.54.0->litellm) (1.3.1)\n",
      "Requirement already satisfied: certifi in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from httpx->arize-phoenix) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from httpx->arize-phoenix) (1.0.6)\n",
      "Requirement already satisfied: idna in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from httpx->arize-phoenix) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from httpcore==1.*->httpx->arize-phoenix) (0.14.0)\n",
      "Collecting protobuf<6.0,>=3.20.2 (from arize-phoenix)\n",
      "  Using cached protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from pandas>=1.0->arize-phoenix) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from pandas>=1.0->arize-phoenix) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from pydantic!=2.0.*,<3,>=1.0->arize-phoenix) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from pydantic!=2.0.*,<3,>=1.0->arize-phoenix) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->litellm) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from requests<3.0.0,>=2.31.0->litellm) (2.2.3)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy<3,>=2.0.4->sqlalchemy[asyncio]<3,>=2.0.4->arize-phoenix)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from tiktoken>=0.7.0->litellm) (2024.9.11)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->litellm)\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->litellm)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->litellm)\n",
      "  Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->litellm)\n",
      "  Using cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->litellm)\n",
      "  Using cached propcache-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->litellm)\n",
      "  Using cached yarl-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (64 kB)\n",
      "Requirement already satisfied: cryptography in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from authlib->arize-phoenix) (43.0.1)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api->openinference-instrumentation-litellm)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc==1.28.1 (from opentelemetry-exporter-otlp->arize-phoenix)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http==1.28.1 (from opentelemetry-exporter-otlp->arize-phoenix)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc==1.28.1->opentelemetry-exporter-otlp->arize-phoenix)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc==1.28.1->opentelemetry-exporter-otlp->arize-phoenix)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: packaging>=18.0 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from opentelemetry-instrumentation->openinference-instrumentation-litellm) (24.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from scikit-learn->arize-phoenix) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->arize-phoenix)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from tokenizers->litellm) (0.25.1)\n",
      "Requirement already satisfied: filelock in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2024.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.7.0->strawberry-graphql==0.243.1->arize-phoenix) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from cryptography->authlib->arize-phoenix) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/bizon/.pyenv/versions/3.11.10/envs/cohere-haystack/lib/python3.11/site-packages (from cffi>=1.12->cryptography->authlib->arize-phoenix) (2.22)\n",
      "Downloading arize_phoenix-5.8.0-py3-none-any.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading strawberry_graphql-0.243.1-py3-none-any.whl (306 kB)\n",
      "Downloading litellm-1.52.8-py3-none-any.whl (6.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openinference_semantic_conventions-0.1.12-py3-none-any.whl (9.1 kB)\n",
      "Downloading openinference_instrumentation_litellm-0.1.5-py3-none-any.whl (10 kB)\n",
      "Downloading arize_phoenix_otel-0.6.1-py3-none-any.whl (10 kB)\n",
      "Downloading arize_phoenix_evals-0.17.4-py3-none-any.whl (57 kB)\n",
      "Downloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
      "Downloading openai-1.54.4-py3-none-any.whl (389 kB)\n",
      "Downloading openinference_instrumentation-0.1.18-py3-none-any.whl (14 kB)\n",
      "Downloading opentelemetry_proto-1.28.1-py3-none-any.whl (55 kB)\n",
      "Using cached protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading SQLAlchemy-2.0.36-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sqlean.py-3.47.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
      "Downloading aiosqlite-0.20.0-py3-none-any.whl (15 kB)\n",
      "Downloading Authlib-1.3.2-py2.py3-none-any.whl (225 kB)\n",
      "Downloading cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Downloading grpc_interceptor-0.15.4-py3-none-any.whl (20 kB)\n",
      "Downloading opentelemetry_api-1.28.1-py3-none-any.whl (64 kB)\n",
      "Downloading opentelemetry_exporter_otlp-1.28.1-py3-none-any.whl (7.0 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.28.1-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.28.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_sdk-1.28.1-py3-none-any.whl (118 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl (159 kB)\n",
      "Downloading opentelemetry_instrumentation-0.49b1-py3-none-any.whl (30 kB)\n",
      "Using cached pyarrow-18.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.0 MB)\n",
      "Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading websockets-14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
      "Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
      "Downloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
      "Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (602 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m602.4/602.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "Using cached propcache-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached yarl-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
      "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Installing collected packages: sqlean-py, websockets, threadpoolctl, scipy, python-dotenv, pyarrow, protobuf, propcache, openinference-semantic-conventions, multidict, Mako, grpc-interceptor, greenlet, graphql-core, frozenlist, deprecated, cachetools, aiosqlite, aioitertools, aiohappyeyeballs, yarl, tiktoken, strawberry-graphql, sqlalchemy, scikit-learn, opentelemetry-proto, opentelemetry-api, googleapis-common-protos, aiosignal, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, openai, authlib, arize-phoenix-evals, alembic, aiohttp, opentelemetry-sdk, opentelemetry-instrumentation, litellm, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, openinference-instrumentation, opentelemetry-exporter-otlp, openinference-instrumentation-litellm, arize-phoenix-otel, arize-phoenix\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.5\n",
      "    Uninstalling protobuf-4.25.5:\n",
      "      Successfully uninstalled protobuf-4.25.5\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.51.0\n",
      "    Uninstalling openai-1.51.0:\n",
      "      Successfully uninstalled openai-1.51.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "haystack-ai 2.6.0 requires numpy<2, but you have numpy 2.0.2 which is incompatible.\n",
      "fastembed 0.3.6 requires numpy<2,>=1.21; python_version < \"3.12\", but you have numpy 2.0.2 which is incompatible.\n",
      "grpcio-tools 1.62.3 requires protobuf<5.0dev,>=4.21.6, but you have protobuf 5.28.3 which is incompatible.\n",
      "sagemaker 2.232.1 requires numpy<2.0,>=1.9.0, but you have numpy 2.0.2 which is incompatible.\n",
      "sagemaker 2.232.1 requires protobuf<5.0,>=3.12, but you have protobuf 5.28.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Mako-1.3.6 aiohappyeyeballs-2.4.3 aiohttp-3.11.2 aioitertools-0.12.0 aiosignal-1.3.1 aiosqlite-0.20.0 alembic-1.14.0 arize-phoenix-5.8.0 arize-phoenix-evals-0.17.4 arize-phoenix-otel-0.6.1 authlib-1.3.2 cachetools-5.5.0 deprecated-1.2.14 frozenlist-1.5.0 googleapis-common-protos-1.66.0 graphql-core-3.2.5 greenlet-3.1.1 grpc-interceptor-0.15.4 litellm-1.52.8 multidict-6.1.0 openai-1.54.4 openinference-instrumentation-0.1.18 openinference-instrumentation-litellm-0.1.5 openinference-semantic-conventions-0.1.12 opentelemetry-api-1.28.1 opentelemetry-exporter-otlp-1.28.1 opentelemetry-exporter-otlp-proto-common-1.28.1 opentelemetry-exporter-otlp-proto-grpc-1.28.1 opentelemetry-exporter-otlp-proto-http-1.28.1 opentelemetry-instrumentation-0.49b1 opentelemetry-proto-1.28.1 opentelemetry-sdk-1.28.1 opentelemetry-semantic-conventions-0.49b1 propcache-0.2.0 protobuf-5.28.3 pyarrow-18.0.0 python-dotenv-1.0.1 scikit-learn-1.5.2 scipy-1.14.1 sqlalchemy-2.0.36 sqlean-py-3.47.0 strawberry-graphql-0.243.1 threadpoolctl-3.5.0 tiktoken-0.8.0 websockets-14.1 yarl-1.17.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install arize-phoenix litellm openinference-semantic-conventions openinference-instrumentation-litellm arize-phoenix-otel arize-phoenix-evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0063934326, -0.04257202, 0.038116455, -0.023880005, -0.048187256, -0.07220459, -0.036224365, 0.0054969788, 0.059173584, -0.04458618, -0.022476196, 0.058624268, -0.0044059753, -0.025939941, 0.07312012, 0.013343811, -0.0029258728, 0.08496094, -0.08483887, 0.06951904, -0.04763794, -0.12573242, 0.022918701, 0.060760498, 0.078308105, 0.047454834, -0.005924225, -0.01197052, -0.030166626, -0.025939941, -0.027023315, 0.013977051, 0.017974854, 0.053497314, 0.014808655, 0.025024414, -0.00058698654, 0.043121338, 0.05053711, -0.015609741, 0.009361267, -0.05593872, -0.05114746, 0.049682617, -0.049682617, 0.08685303, 0.013916016, -0.0055122375, -0.095458984, 0.056762695, -0.05355835, -0.01687622, 0.052581787, -0.09124756, 0.033569336, -0.00819397, 0.072143555, -0.064575195, -0.010772705, 0.14697266, 0.024642944, -0.04220581, 0.05886841, 0.07775879, 0.08416748, 0.011276245, -0.059539795, 0.011634827, -0.101623535, 0.0362854, -0.09362793, 0.0013771057, 0.007610321, 0.045898438, 0.09240723, 0.032592773, 0.020248413, -0.09710693, 0.01309967, -0.018661499, 0.022842407, -0.074035645, -0.013397217, -0.06506348, -0.020233154, 0.0206604, 0.08227539, 0.0129470825, 0.034423828, -0.031921387, -0.016311646, -0.020019531, -0.018417358, -0.064575195, -0.03111267, 0.0040664673, 0.0058288574, -0.014587402, -0.07757568, -0.101379395, -0.0016298294, -0.107910156, -0.023391724, -0.09832764, -0.09613037, 0.07635498, -0.025360107, 0.0059318542, -0.059417725, -0.048553467, -0.022216797, 0.040527344, 0.08288574, -0.01184082, 0.050720215, 0.14160156, -0.006801605, 0.012489319, 0.06188965, -0.06530762, 0.053863525, 0.0020542145, -0.020126343, -0.021896362, 0.06750488, 0.0390625, 0.0022354126, 0.04852295, 0.06149292, -0.011978149, -0.02281189, -0.009994507, 0.010627747, 0.028320312, -0.06939697, 0.04309082, -0.047576904, 0.016113281, -0.049346924, 0.01184845, 0.046905518, -0.018249512, -0.056121826, 0.061798096, 0.022521973, -0.007911682, 0.03982544, -0.033294678, 0.068115234, 0.0013713837, 0.032836914, 0.053649902, 0.036224365, -0.03555298, -0.0335083, 0.03149414, -0.06335449, -0.025756836, -0.015556335, 0.013511658, 0.020690918, 0.047576904, -0.07244873, -0.039916992, 0.026107788, 0.07739258, -0.050872803, -0.035827637, 0.0053596497, 0.022079468, 0.08111572, -0.00920105, 0.08758545, 0.07751465, 0.05557251, 0.00089502335, -0.042999268, 0.052978516, 0.015975952, -0.01939392, -0.019760132, -0.047576904, -0.12597656, 0.10986328, 0.051513672, 0.01638794, -0.0049819946, 0.0435791, -0.014427185, 0.011367798, 0.00868988, 0.041748047, 0.015609741, 0.0105896, -0.028289795, -0.05126953, -0.095825195, 0.001364708, 0.048736572, 0.0206604, 0.04827881, -0.03756714, 0.013717651, 0.06365967, -0.018295288, 0.09460449, -0.024459839, -0.11431885, -0.02355957, -0.024368286, 0.052764893, -0.05126953, 0.007896423, -0.020568848, 0.039245605, -0.08081055, -0.09851074, -0.03515625, 0.04626465, 0.019943237, 0.046081543, -0.02394104, 0.005847931, -0.0036716461, -0.026733398, -0.016326904, 0.036315918, -0.113342285, -0.019042969, 0.059448242, 0.0390625, -0.015930176, 0.026733398, -0.026351929, -0.030090332, 0.04373169, -0.030380249, -0.003282547, -0.055725098, -0.028549194, -0.049957275, -0.02003479, 0.111694336, -0.018005371, -0.017425537, -0.072509766, 0.038238525, 0.009498596, 0.044891357, 0.02331543, -0.046417236, 0.013694763, -0.10180664, 0.012229919, 0.09307861, 0.05886841, 0.00945282, -0.057373047, -0.008735657, -0.06768799, 0.05050659, -0.091674805, -0.04888916, 0.039215088, 0.0135269165, 0.030975342, 0.06121826, -0.04119873, 0.00157547, -0.015701294, 0.0038166046, 0.05593872, -7.43866e-05, -0.024490356, -0.080200195, -0.017974854, 0.05810547, 0.09820557, -0.011253357, 0.022033691, 0.06567383, -0.09289551, 0.016479492, 0.019424438, -0.059814453, 0.0960083, -0.03189087, 0.00023007393, 0.015464783, 0.05923462, -0.04928589, 0.01586914, -0.028961182, 0.09033203, -0.05621338, -0.013175964, -0.038391113, -0.017105103, 0.03793335, 0.01889038, 0.06427002, -0.036621094, -0.0317688, 0.07342529, 0.03111267, -0.044952393, 0.03112793, -0.033966064, -0.13012695, 0.050048828, 0.0032024384, 0.08154297, -0.02281189, -0.053649902, -0.043792725, 0.0013484955, 0.0038661957, 0.024765015, 0.02331543, 0.040374756, -0.019210815, 0.017028809, 0.030975342, -0.030349731, 0.00080251694, -0.020065308, 0.04714966, -0.07348633, -0.028900146, -0.046203613, -0.030715942, 0.045318604, 0.042053223, -0.057922363, 0.03186035, -0.022232056, -0.016952515, 0.00024461746, -0.020431519, 0.0597229, 0.03555298, 0.09436035, -0.028427124, 0.06921387, 0.03237915, -0.046813965, -0.01285553, -0.034057617, -0.039733887, -0.014381409, -0.07714844, -0.10571289, 0.06719971, -0.022872925, -0.15405273, 0.026748657, -0.06222534, 0.014007568, 0.08459473, -0.011955261, -0.054473877, -0.02607727, 0.0075950623, -0.04550171, 0.02053833, 0.022323608, -0.052520752, 0.091796875, -0.0019779205, 0.013008118, 0.07208252, -0.08502197, 0.022094727, -0.07165527, 0.08154297, -0.00069999695, -0.06335449, 0.034698486, 0.05847168, -0.070739746, 0.0054016113, -0.01374054, 0.123168945, -0.029678345]\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from litellm import completion, embedding, rerank, litellm\n",
    "import os\n",
    "os.environ[\"COHERE_API_KEY\"] = \"mpEie8xjPjKIhHz7wCbwxzxWaMEkojhc6ZhO8U82\"\n",
    "\n",
    "embedding_response = embedding(\n",
    "    input=[\"Testing testing 123\"], \n",
    "    input_type=\"search_query\", \n",
    "    model=f\"cohere/embed-multilingual-light-v3.0\"\n",
    ")\n",
    "\n",
    "# print(embedding_response.data[0].embedding)\n",
    "print(embedding_response.data[0]['embedding'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['And an irrelevant doc', 'This is a test document', 'This is another test document']\n",
      "['This is a test document', 'This is another test document']\n"
     ]
    }
   ],
   "source": [
    "documents = [\"And an irrelevant doc\", \"This is a test document\", \"This is another test document\"]\n",
    "\n",
    "print(documents)\n",
    "\n",
    "reranked_response = rerank(\n",
    "    query=\"Testing testing 123\",\n",
    "    documents=documents,\n",
    "    top_n=2,\n",
    "    model=f\"cohere/rerank-multilingual-v3.0\",\n",
    "    return_documents=True\n",
    ")\n",
    "\n",
    "reranked_documents = [documents[result['index']] for result in reranked_response.results]\n",
    "\n",
    "print(reranked_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I can't find any information on the meaning of life. One document suggests it is popcorn, but this is contradicted by another."
     ]
    }
   ],
   "source": [
    "documents = [\n",
    "    {     \n",
    "        'id': '1',   \n",
    "        \"data\": {\n",
    "            \"title\": \"This is a test document\",\n",
    "            \"snippet\": \"This is a test document that contains some sample text. The meaning of life is popcorn. It discusses various topics and serves as an example for testing purposes. The document includes multiple sentences to demonstrate a typical paragraph structure.\",\n",
    "            \"publication_date\": \"2024-01-01\",\n",
    "            \"multipality\": \"Almelo\"\n",
    "        }\n",
    "    },\n",
    "    {     \n",
    "      'id': '2',   \n",
    "        \"data\": {\n",
    "            \"title\": \"This is another test document\",\n",
    "            \"snippet\": \"This is another test document that contains some sample text. It discusses various topics and serves as an example for testing purposes. The document includes multiple sentences to demonstrate a typical paragraph structure.\",\n",
    "            \"publication_date\": \"2024-01-01\",\n",
    "            \"multipality\": \"Deventer\"\n",
    "        }\n",
    "    },\n",
    "    {     \n",
    "        'id': '3',   \n",
    "        \"data\": {\n",
    "            \"title\": \"And an irrelevant doc\",\n",
    "            \"snippet\": \"This is an irrelevant document that contains some sample text. The meaning of life is definately not popcorn. It discusses various topics and serves as an example for testing purposes. The document includes multiple sentences to demonstrate a typical paragraph structure.\",\n",
    "            \"publication_date\": \"2024-01-01\",\n",
    "            \"multipality\": \"Zwolle\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "docs = [\n",
    "    {     \n",
    "        'id': '1',   \n",
    "        \"title\": \"This is a test document\",\n",
    "        \"snippet\": \"This is a test document that contains some sample text. The meaning of life is popcorn. It discusses various topics and serves as an example for testing purposes. The document includes multiple sentences to demonstrate a typical paragraph structure.\",\n",
    "        \"publication_date\": \"2024-01-01\",\n",
    "        \"multipality\": \"Almelo\"\n",
    "    },\n",
    "    {     \n",
    "        'id': '2',   \n",
    "        \"title\": \"This is another test document\",\n",
    "        \"snippet\": \"This is another test document that contains some sample text. It discusses various topics and serves as an example for testing purposes. The document includes multiple sentences to demonstrate a typical paragraph structure.\",\n",
    "        \"publication_date\": \"2024-01-01\",\n",
    "        \"multipality\": \"Deventer\"\n",
    "    },\n",
    "    {     \n",
    "        'id': '3',   \n",
    "        \"title\": \"And an irrelevant doc\",\n",
    "        \"snippet\": \"This is an irrelevant document that contains some sample text. The meaning of life is definately not popcorn. It discusses various topics and serves as an example for testing purposes. The document includes multiple sentences to demonstrate a typical paragraph structure.\",\n",
    "        \"publication_date\": \"2024-01-01\",\n",
    "        \"multipality\": \"Zwolle\"\n",
    "    }\n",
    "]\n",
    "\n",
    "context = \"\\n\".join([f\"Document ID {doc['id']}\\nTitle: {doc['data']['title']}\\nPublication date: {doc['data']['publication_date']}\\nMultipality: {doc['data']['multipality']}\\nSnippet: {doc['data']['snippet']}\\n\\n\" for doc in documents])\n",
    "query = \"What is the meaning of life?\"\n",
    "\n",
    "messages_with_context = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': 'You are a helpful assistant that can answer questions and provide information.'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        \"content\": f\"\"\"Context: {context}\\n\\nQuestion: {query}\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "msgs = [\n",
    "    {\n",
    "        'role': 'system',\n",
    "        'content': 'You are a helpful assistant that can answer questions and provide information.'\n",
    "    },\n",
    "    {\n",
    "        'role': 'user',\n",
    "        \"content\": f\"{query}\"\n",
    "    }\n",
    "]\n",
    "\n",
    "os.environ['LITELLM_LOG'] = 'DEBUG'\n",
    "# litellm.callbacks = [\"arize\"]\n",
    "# litellm.failure_callback=[\"sentry\"]\n",
    "# litellm.input_callback=[\"sentry\"] # adds sentry breadcrumbing\n",
    "# litellm.failure_callback=[\"sentry\"] # [OPTIONAL] if you want litellm to capture -> send exception to sentry\n",
    "litellm.turn_off_message_logging=True\n",
    "\n",
    "\n",
    "\n",
    "# completion_response = completion(\n",
    "#     model=\"cohere/command-r-plus\",\n",
    "#     instructions=\"You are a helpful assistant that can answer questions and provide information.\",\n",
    "#     messages=messages_without_context,\n",
    "#     documents=documents_without_data,\n",
    "#     return_citations=True\n",
    "# )\n",
    "\n",
    "# from pprint import pprint\n",
    "# pprint(completion_response.dict(), indent=2, width=80)\n",
    "\n",
    "completion_streaming_response = completion(\n",
    "    model=\"cohere/command-r-plus\",\n",
    "    instructions=\"You are a helpful assistant that can answer questions and provide information.\",\n",
    "    messages=msgs,\n",
    "    documents=docs,\n",
    "    citation_quality=\"accurate\",\n",
    "    return_citations=True,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "raw_chunks = []\n",
    "for chunk in completion_streaming_response: \n",
    "    # Print the text as it comes\n",
    "    if chunk.choices[0].delta.content:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")\n",
    "    \n",
    "    # Citations will be in the final chunk\n",
    "    if hasattr(chunk, 'citations'):\n",
    "        print(\"\\n\\nCitations:\", chunk.citations)\n",
    "\n",
    "# from pprint import pprint\n",
    "# # Handle streaming response with citations\n",
    "# def process_stream_with_citations(response):\n",
    "#     full_response = \"\"\n",
    "#     citations = []\n",
    "    \n",
    "#     for chunk in response:  \n",
    "#         print(f'AAAAAAAAAAA:')\n",
    "#         pprint(chunk)\n",
    "#         continue\n",
    "    \n",
    "#     print(f\"full_response: {full_response}\")\n",
    "#     print(f\"citations({len(citations)})\")\n",
    "#     # Print collected citations at the end\n",
    "#     if citations:\n",
    "#         print(\"\\n\\nCitations:\")\n",
    "#         for citation in citations:\n",
    "#             print(f\"- {citation}\")\n",
    "    \n",
    "#     return full_response, citations\n",
    "\n",
    "# # Process the streaming response\n",
    "# full_response, citations = process_stream_with_citations(completion_streaming_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choices(finish_reason='stop', index=0, message=Message(content=\"I'm sorry, I can't find any information on the meaning of life. One document suggests it is popcorn, but another refutes this.\", role='assistant', tool_calls=None, function_call=None))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion_streaming_response.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cohere-haystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
